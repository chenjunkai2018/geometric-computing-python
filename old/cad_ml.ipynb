{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAD Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "The ABC dataset offers 1 Million CAD files and a specialized library to process the files and generate arbitrary dense meshes and point clouds. The library can be installed with `conda install -c pythonocc -c oce -c dlr-sc -c conda-forge -c tpaviot -c skoch9 cadmesh`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cadmesh as cm\n",
    "import meshplot as mp\n",
    "import numpy as np\n",
    "import igl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meshing CAD files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_coarse = cm.mesh_model(\"data/test1.step\", max_size=4e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp.plot(m_coarse[\"vertices\"], m_coarse[\"face_indices\"], shading={\"wireframe\": True, \"wire_width\": 1.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_dense = cm.mesh_model(\"data/test1.step\", max_size=2e-5)\n",
    "mp.plot(m_dense[\"vertices\"], m_dense[\"face_indices\"], shading={\"wireframe\": True, \"wire_width\": 1.0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ground Truth Quantities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import read_model\n",
    "\n",
    "m = read_model(\"data/test1_trimesh.obj\", \"data/test1_features.yml\")\n",
    "\n",
    "# Average normals at vertices with multiple normals\n",
    "av_normals = cm.get_averaged_normals(m)\n",
    "\n",
    "# Determine normals with uniform weighting in libigl\n",
    "normals = igl.per_vertex_normals(m[\"vertices\"], m[\"face_indices\"].astype(\"int64\"))\n",
    "\n",
    "# Plot the model\n",
    "p = mp.plot(m[\"vertices\"], m[\"face_indices\"], return_plot=True)\n",
    "\n",
    "# Add normals to the plot\n",
    "p.add_lines(m[\"vertices\"], m[\"vertices\"] + normals * 2.0, shading={\"line_color\": \"red\"});\n",
    "p.add_lines(m[\"vertices\"], m[\"vertices\"] + av_normals * 2.0, shading={\"line_color\": \"black\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Curves and Patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the surface patches\n",
    "c = np.zeros(m[\"face_indices\"].shape[0])\n",
    "for i, fe in enumerate(m[\"features\"][\"surfaces\"]):\n",
    "    for j in fe[\"face_indices\"]:\n",
    "        c[j] = i\n",
    "\n",
    "# Visualize the patches\n",
    "mp.plot(m[\"vertices\"], m[\"face_indices\"], c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the surface patch types\n",
    "t_map = {\"Plane\": 0, \"Cylinder\": 1, \"Cone\": 2, \"Sphere\": 3, \"Torus\": 4, \"Bezier\": 5,\n",
    "         \"BSpline\": 6, \"Revolution\": 7,\"Extrusion\": 8, \"Other\": 9}\n",
    "\n",
    "c1 = np.zeros(m[\"face_indices\"].shape[0])\n",
    "for i, fe in enumerate(m[\"features\"][\"surfaces\"]):\n",
    "    t = t_map[fe[\"type\"]]\n",
    "    for j in fe[\"face_indices\"]:\n",
    "        c1[j] = t\n",
    "\n",
    "# Visualize the patch types\n",
    "mp.plot(m[\"vertices\"], m[\"face_indices\"], c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the surface patch vertices\n",
    "c2 = np.zeros(m[\"vertices\"].shape[0])\n",
    "for i, fe in enumerate(m[\"features\"][\"surfaces\"]):\n",
    "    for j in fe[\"vert_indices\"]:\n",
    "        c2[j] = i\n",
    "\n",
    "# Visualize the vertices\n",
    "mp.plot(m[\"vertices\"], c=c2, shading={\"point_size\": 10.})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the sharp features\n",
    "lines = []\n",
    "for i, fe in enumerate(m[\"features\"][\"curves\"]):\n",
    "    if fe[\"sharp\"]:\n",
    "        for j in range(len(fe[\"vert_indices\"])-1):\n",
    "            lines.append([fe[\"vert_indices\"][j], fe[\"vert_indices\"][j+1]])        \n",
    "\n",
    "# Visualize the sharp features            \n",
    "p = mp.plot(m[\"vertices\"], m[\"face_indices\"], c, return_plot=True)\n",
    "p.add_edges(m[\"vertices\"], np.array(lines), shading={\"line_color\": \"red\", \"line_width\": 2.5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "For the learning examples we use [Pytorch](https://pytorch.org/) and [Pytorch Geometric](https://pytorch-geometric.readthedocs.io/en/latest/) that can be installed according to their documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Sequential as Seq, Dropout, Linear as Lin\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.nn import DynamicEdgeConv\n",
    "\n",
    "from utils import MLP\n",
    "from utils import ABCDataset\n",
    "import meshplot as mp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_train = T.Compose([\n",
    "    T.FixedPoints(100),\n",
    "    T.RandomTranslate(0.002),\n",
    "    T.RandomRotate(15, axis=0),\n",
    "    T.RandomRotate(15, axis=1),\n",
    "    T.RandomRotate(15, axis=2)\n",
    "])\n",
    "tf_test = T.Compose([\n",
    "    T.FixedPoints(2000)\n",
    "])\n",
    "tf_pre = T.NormalizeScale()\n",
    "\n",
    "typ = \"Curves\"\n",
    "train_dataset = ABCDataset(\"data/ml/ABC\", train=True, typ=typ, transform=tf_train, pre_transform=tf_pre)\n",
    "test_dataset = ABCDataset(\"data/ml/ABC\", train=False, typ=typ, transform=tf_test, pre_transform=tf_pre)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=5, shuffle=True, num_workers=6)\n",
    "test_loader = DataLoader(test_dataset, batch_size=5, shuffle=False, num_workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = test_dataset\n",
    "#print(len(dataset), dataset.num_classes, dataset.num_node_features)\n",
    "\n",
    "d = dataset[4]\n",
    "v = d.pos.cpu().numpy()\n",
    "y = d.y.cpu().numpy()\n",
    "\n",
    "if typ == \"Curves\":\n",
    "    p = mp.plot(v, c=-y, shading={\"point_size\": 0.15})\n",
    "\n",
    "if typ == \"Normals\":\n",
    "    c = y * 0.5 + 0.5\n",
    "    c = np.linalg.norm(c, axis=1)\n",
    "    p = mp.plot(v, c=c, shading={\"point_size\": 0.15}, return_plot=True)\n",
    "\n",
    "    p.add_lines(v, v + y * 0.05)\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, out_channels, k=30, aggr='max', typ='Curves'):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.conv1 = DynamicEdgeConv(MLP([2 * 3, 64, 64]), k, aggr)\n",
    "        self.conv2 = DynamicEdgeConv(MLP([2 * 64, 64, 64]), k, aggr)\n",
    "        self.conv3 = DynamicEdgeConv(MLP([2 * 64, 64, 64]), k, aggr)\n",
    "        self.lin1 = MLP([3 * 64, 1024])\n",
    "\n",
    "        self.mlp = Seq(\n",
    "            MLP([1024, 256]), Dropout(0.5), MLP([256, 128]), Dropout(0.5),\n",
    "            Lin(128, out_channels))\n",
    "\n",
    "    def forward(self, data):\n",
    "        pos, batch = data.pos, data.batch\n",
    "        x1 = self.conv1(pos, batch)\n",
    "        x2 = self.conv2(x1, batch)\n",
    "        x3 = self.conv3(x2, batch)\n",
    "        out = self.lin1(torch.cat([x1, x2, x3], dim=1))\n",
    "        out = self.mlp(out)\n",
    "        if typ == \"Curves\":\n",
    "            return F.log_softmax(out, dim=1)\n",
    "        if typ == \"Normals\":\n",
    "            return F.normalize(out, p=2, dim=-1)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net(train_dataset.num_classes, k=30).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Train and Test Procedures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cosine_Loss(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Cosine_Loss,self).__init__()\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        dotp = torch.mul(x, y).sum(1)\n",
    "        angle = torch.sum(torch.acos(torch.abs(dotp))) / x.shape[0]\n",
    "        loss = torch.sum(1 - dotp.pow(2)) / x.shape[0]\n",
    "        return loss, angle\n",
    "\n",
    "cosine_loss = Cosine_Loss()\n",
    "\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "\n",
    "    total_loss = correct_nodes = total_nodes = 0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        if typ == \"Curves\":\n",
    "            loss = F.nll_loss(out, data.y)\n",
    "        if typ == \"Normals\":\n",
    "            loss, angle = cosine_loss(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        if typ == \"Curves\":\n",
    "            correct_nodes += out.max(dim=1)[1].eq(data.y).sum().item()\n",
    "            total_nodes += data.num_nodes\n",
    "            acc = correct_nodes / total_nodes\n",
    "        if typ == \"Normals\":\n",
    "            acc = angle.item()*180/np.pi\n",
    "        \n",
    "        print('[{}/{}] Loss: {:.4f}, Train Accuracy: {:.4f}'.format(i + 1, len(train_loader), total_loss / 10, acc))\n",
    "            \n",
    "        total_loss = correct_nodes = total_nodes = 0\n",
    "\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "\n",
    "    correct_nodes = total_nodes = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        with torch.no_grad():\n",
    "            out = model(data)\n",
    "            \n",
    "        if typ == \"Curves\":\n",
    "            pred = out.max(dim=1)[1]\n",
    "            correct_nodes += pred.eq(data.y).sum().item()\n",
    "            total_nodes += data.num_nodes\n",
    "            \n",
    "        if typ == \"Normals\":\n",
    "            _, angle = cosine_loss(out, data.y)\n",
    "            correct_nodes += angle.item() * 180 / np.pi\n",
    "            total_nodes += 1\n",
    "            \n",
    "    return correct_nodes / total_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Training and Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, 2):\n",
    "    train()\n",
    "    acc = test(test_loader)\n",
    "    print('Epoch: {:02d}, Accuracy: {:.4f}'.format(epoch, acc))\n",
    "    torch.save(model.state_dict(), \"data/ml/ABC/models/%02i_%.2f.dat\"%(epoch, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net(train_dataset.num_classes, k=30)\n",
    "model.load_state_dict(torch.load(\"data/ml/ABC/models/m_022_0.9606.dat\", map_location='cpu'));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = test_loader\n",
    "\n",
    "for d in loader:\n",
    "    with torch.no_grad():\n",
    "        out = model(d.to(device))\n",
    "    \n",
    "    m = 4\n",
    "    v = d.pos[d.batch == m].cpu().numpy()\n",
    "    y = d.y[d.batch == m].cpu().numpy()\n",
    "    \n",
    "    \n",
    "    if typ == \"Curves\":\n",
    "        e = out.max(dim=1)[1][d.batch == m].cpu().numpy()\n",
    "        p = mp.subplot(v, c=-y, shading={\"point_size\": 0.15}, s=[1, 2, 0])\n",
    "        mp.subplot(v, c=-e, shading={\"point_size\": 0.15}, s=[1, 2, 1], data=p)\n",
    "\n",
    "    if typ == \"Normals\":\n",
    "        n = out[d.batch == m].cpu().numpy()\n",
    "        nc = n * 0.5 + 0.5\n",
    "        nc = np.linalg.norm(nc, axis=1)\n",
    "        c = y * 0.5 + 0.5\n",
    "        c = np.linalg.norm(c, axis=1)\n",
    "        p = mp.subplot(v, c=-c, shading={\"point_size\": 0.15}, s=[1, 2, 0])\n",
    "        mp.subplot(v, c=-nc, shading={\"point_size\": 0.15}, s=[1, 2, 1], data=p)\n",
    "\n",
    "        p.rows[0][0].add_lines(v, v + y * 0.05)\n",
    "        p.rows[0][1].add_lines(v, v + n * 0.05)\n",
    "    break\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = test(test_loader)\n",
    "print('Accuracy: {:.4f}'.format(acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (course)",
   "language": "python",
   "name": "course"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
